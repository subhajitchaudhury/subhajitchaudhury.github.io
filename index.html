<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #fffed0;
    }
  </style>
  <link rel="icon" type="image/png" href="seal_icon.png">
  <title>Subhajit Chaudhury </title>
    <style type="text/css"></style></head>
        <body><table border="0" width="980px" align="center"><tbody><tr><td>
        
             </td><td valign="top">
    <!--            <img src="images/cmuscslogo.gif">
                    <img src="images/rilogo.png"> -->
            <br>
            <table style="font-size: 12pt;" border="0" width="100%">
                <tbody><tr>
                    <td width="50%">
                        <!-- <img width="300" src="./index_files/mypic.jpeg" border="0"> -->
                        <!-- <img width="300" src="./index_files/mypic2.jpg" border="0"> -->
                        <img width="220" src="./images/subho_small.JPG" border="0"> 
                    </td>
                    <td>
                        <font face="helvetica , ariel, &#39;sans serif&#39;" size="6"> 
                            <b>Subhajit Chaudhury</b><br><br>
                        </font>
                        <font face="helvetica , ariel, &#39;sans serif&#39;" size="4"> 
                            Research Scientist, IBM Research, Tokyo<br>
                            <!-- EECS PhD student, The University of Tokyo<br><br> -->
                            <a href="mailto:subhajitiitb14@gmail.com">subhajitiitb14 at gmail.com</a><br>
                            <!-- [<a href="https://github.com/hiyaroy12" border="0">GitHub</a>] -->
                            [<a href=https://scholar.google.co.jp/citations?user=EBTpFrQAAAAJ&hl=en" border="0">Google Scholar</a>]
                            [<a href="./Subhajit_CV.pdf" border="0">CV</a>]
                            [<a href="https://www.linkedin.com/in/subhajit-chaudhury-24955455"> LinkedIn</a>]<br>
                        </font>
                    </td>
                </tr>
            </tbody></table> 
            <p>
            </p><hr size="2" align="left" noshade="">
        <font face="helvetica, ariel, &#39;sans serif&#39;">
        <h3>About me </h3> 
             
        <span style="font-size: 12pt;">
         
          I am a Research Scientist at <a href="http://www.research.ibm.com/labs/tokyo/">IBM Research, Tokyo</a> working on Reinforcement Learning, Neuro-Symbolic AI and Computer Vision. I obtained my Ph.D. from the University of Tokyo working with <a href="https://www.hal.t.u-tokyo.ac.jp/~yamasaki/index-e.html">Prof. Toshihiko Yamasaki</a> on the topic of robust deep learning methods against adversarial vulnerabilities in neural networks. I received my master's degree in Electrical Engineering from <a href="http://www.iitb.ac.in/">IIT Bombay</a> in 2014 working with Prof. <a href="https://www.ee.iitb.ac.in/~sc/">Subhasis Chaudhuri</a>. I recieved my bachelor's degree in Electrical Engineering from <a href="http://www.jaduniv.edu.in/">Jadavpur University</a> in 2012. </span>.

        </p><hr size="2" align="left" noshade="">

        <h3>News </h3> 
        <font face="helvetica, ariel, &#39;sans serif&#39;">
          <b>[Sept 2021]</b> Papers on "<a href="https://2021.emnlp.org/">Neuro-symbolic Approaches for Text-Based Policy Learning</a>" and "<a href="https://2021.emnlp.org/">Neuro-symbolic Reinforcement Learning with First-Order Logic</a>" are accepted to EMNLP 2021.<br> 
            
          <!-- <b>[Sept 2021]</b> Paper on "<a href="https://2021.emnlp.org/">Neuro-symbolic Reinforcement Learning with First-Order Logic</a>" is accepted to EMNLP 2021.<br>  -->

          <b>[June 2021]</b> Paper on "<a href="https://ieeexplore.ieee.org/document/9502126/">Adversarial Training Time Attack Against Discriminative and Generative Convolutional Models</a>" is accepted to IEEE Access 2021.<br> 

          <b>[Apr 2021]</b> Paper on "<a href="https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging/volume-30/issue-02/023016/Image-inpainting-using-frequency-domain-priors/10.1117/1.JEI.30.2.023016.full?SSO=1">Image inpainting using frequency-domain priors</a>" is accepted to SPIE Journal of Electronic Imaging 2021.<br> 

          <b>[Feb 2021]</b> Paper on "<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9366477">Robustness of Adaptive Neural Network Optimization under Training Noise</a>" is accepted to IEEE Access.<br> 
          <!-- <span style="font-size: 10pt;"> -->
          <b>[Sept 2020]</b> Paper on "<a href="https://www.aclweb.org/anthology/2020.emnlp-main.241.pdf">Improving Generalization in Text-based Reinforcement Learning</a>" is accepted in EMNLP 2020.<br> 

          <b>[July 2020]</b> Work on <a href="https://voicy.jp/channel/865/87438"></a>weakly supervised rally detection in table tennis videos</a> received multiple media coverage: <a href="https://voicy.jp/channel/865/87438">Nikkei Voicy</a>, <a href="https://www.sbbit.jp/article/bitsp2/37830#continue_reading">Softbank Creative - Business+IT</a>, <a href="https://newswitch.jp/p/22822">Nikkan Kogyo Shimbun</a>, <a href="https://japan.zdnet.com/article/35155927">ZDNet</a> and Hokkaido Shimbun.<br> 

          <b>[April 2020]</b> Crack detection work was featured in press release by <a href="https://jpn.nec.com/press/202003/20200331_03.html">NEC Japan</a> and <a href="https://www.nikkei.com/article/DGXMZO57409840Q0A330C2LKA000/">Nikkei newspaper</a>.<br> 

            <!-- <b>[March 2020]</b> Paper on "<a href="https://arxiv.org/pdf/2001.05878.pdf">Robustness of Deep learning in Dermatological Workflow</a>" is accepted in ACM CHIL 2020 [Spotlight paper].<br> -->

            <!-- <b>[Feb 2020]</b> aper on "<a href="https://arxiv.org/pdf/2003.06646.pdf">Adversarial Distribution Shifts</a>" is accepted in IEEE ICASSP 2020.<br> -->

            <!-- <b>[Feb 2020]</b> Recieved travel scholarship for attenting <a href="https://aaai.org/Conferences/AAAI-20/aaai20dccall">Doctoral Consortium</a> at AAAI 2020 in New York.<br> -->

            <!-- <b>[Dec 2019]</b> Presented our paper on "<a href="https://arxiv.org/pdf/2002.08097.pdf">Event Detection in Sports Videos</a>" at IEEE ISM 2019.<br> -->

            <!-- <b>[Sept 2019]</b> Paper on "<a href="http://openaccess.thecvf.com/content_WACV_2020/papers/Kimura_Adversarial_Discriminative_Attention_for_Robust_Anomaly_Detection_WACV_2020_paper.pdf">Adversarial Anomaly Detection</a>" is accepted in IEEE WACV 2020.<br> -->
            <!-- </span> -->
        </p><hr size="2" align="left" noshade="">
        

        <!-- </p><hr size="2" align="left" noshade="">
        <font face="helvetica, ariel, &#39;sans serif&#39;"></font>
        <h3>Work Experience</h3>
        <ul style="list-style-type:circle;">
        <li> <span style="font-size: 12pt;">
        <b><a href="https://www.jpl.nasa.gov/">IBM Research AI, Tokyo, Japan</a></b></span>
        <br>
        <span style="font-size: 11pt;">
        <strong>Position:</strong> Research Scientist [Apr 2017-Present]
        <br>
        At IBM Research, I am working on robust reward estimation for imitation learning from videos and text-based games. Additionally, I am also involved in learning multi-modal emdebbings to represent common concepts between images and textual description. </a> </span>
        <br><br>
        <li> <span style="font-size: 12pt;">
        <b><a href="https://jpn.nec.com/rd/labs/datascience/index.html">NEC Data Science Research Laboratories, Japan:</a></b></span>
        <br>
        <span style="font-size: 12pt;">
        <strong>Position:</strong> Researcher [Oct 2014-Mar 2017] 
        <br>
        At NEC, I worked on deep learning based crack detection from videos captured using inspection vehicles. Our crack detection system was used for inspections of road cracks in Texas, USA. Additionally, our system was used to find defects on the runaway in the Nanki-Shirahama airport in Wakayama, Japan. </a> </span>
        <br><br>
      </span>
    </p><hr size="2" align="left" noshade=""> -->


    <h3>Work Experience</h3>

    <ul style="list-style-type:circle;">
    <li> <span style="font-size: 12pt;">
    <b><a href="http://www.research.ibm.com/labs/tokyo/">IBM Research, Tokyo, Japan</a></b></span>
    <br>
    <span style="font-size: 11pt;">
    <strong>Position:</strong> Research Scientist [Apr 2017-Present]
    <br>
    At IBM Research, I work on reinforcement learning algorithms applied to dialog-based systems and imitation learning from videos. Additionally, I am also involved in applied research for weakly supervised event detection from videos. </a> </span>
    <br><br>
    <!-- <li> <span style="font-size: 12pt;">
    <b><a href="https://jpn.nec.com/rd/labs/datascience/index.html">NEC Data Science Research Laboratories, Japan:</a></b></span>
    <br>
    <span style="font-size: 11pt;">
    <strong>Position:</strong> Research Intern [Jan 2017-Mar 2017] 
    <br>
    At NEC, I did an internship under <a href="https://www.researchgate.net/profile/Masato_Tsukada">Dr. Masato Tsukada</a> and <a href="https://www.researchgate.net/profile/Kenta_Senzaki">Mr. Kenta Senzaki</a> 
    on satellite image analysis using deep learning. </a> </span>
    <br><br> -->
        
    <li> <span style="font-size: 12pt;">
    <b><a href="https://jpn.nec.com/rd/labs/datascience/index.html">NEC Research Laboratories, Japan</a></b></span>
    <br>
    <span style="font-size: 11pt;">
    <strong>Position:</strong> Researcher [Oct 2014-Mar 2017] 
    <br> 
    At NEC, I worked on deep learning based crack detection from videos. Our crack detection system was used for inspections of road cracks in Texas, USA. Additionally, our system was used to find defects on the runaway in the Nanki-Shirahama airport in Wakayama, Japan. </a> </span></ul>

    </p><hr size="2" align="left" noshade="">

    <font face="helvetica, ariel, &#39;sans serif&#39;"></font>
    <h3>Publications </h3> 
    <span style="font-size: 12pt;">
      <!-- My research interests are in the intersection of reinforcement learning and computer vision. At IBM, I am
      working on robust reward estimation for imitation learning from videos and text-based games. In my Ph.D. work, I am
      focusing on exploring robust deep leanring methods against adversarial attacks. -->
    <!-- </p><hr size="2" align="left" noshade="">
    <p> -->

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">


          <!--Subha's EMNLP Submission-->
          <tr onmouseout="emnlp20_stop()" onmouseover="emnlp20_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='emnlp20_image'><img src='images/emnlp_crest_cropped.png'></div>
                <img src='images/emnlp_crest_cropped.png'>
              </div>
              <script type="text/javascript">
                function emnlp20_start() {
                  document.getElementById('emnlp20_image').style.opacity = "1";
                }
                function emnlp20_stop() {
                  document.getElementById('emnlp20_image').style.opacity = "0";
                }
                arxiv_vigan_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://www.aclweb.org/anthology/2020.emnlp-main.241.pdf">
                <papertitle>Bootstrapped Q-learning with Context Relevant Observation Pruning to Generalize in Text-based Games</papertitle>
              </a>
              <br>
              <strong>Subhajit Chaudhury</strong>, Daiki Kimura, Kartik Talamadupula, Michiaki Tatsubori, Asim Munawar and Ryuki Tachibana
              <br>
              <em>Empirical Methods in Natural Language Processing (EMNLP)</em>, 2020.
              <br>
              <a href="https://arxiv.org/pdf/2009.11896.pdf">arxiv</a> /
              <a href="https://slideslive.com/38938770/bootstrapped-qlearning-with-context-relevant-observation-pruning-to-generalize-in-textbased-games">video</a> / 
              <a href="http://ibm.biz/crest-rl">code</a>
              <p></p>
              <!--<p>Learn an internal model of observation to estimate rewards without completely learning the dynamics-->
                <!--of the external environment for imitation learning from observations.</p>-->
            </td>
          </tr>


          <!--Subha's ICASSP Submission-->
          <tr onmouseout="icassp20_stop()" onmouseover="icassp20_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='icassp20_evo'><img src='images/icassp20_evo_cropped.png'></div>
                <img src='images/icassp20_evo_cropped.png'>
              </div>
              <script type="text/javascript">
                function icassp20_start() {
                  document.getElementById('icassp20_evo').style.opacity = "1";
                }

                function icassp20_stop() {
                  document.getElementById('icassp20_evo').style.opacity = "0";
                }
                arxiv_vigan_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://ieeexplore.ieee.org/document/9053263">
                <papertitle>Investigating Generalization in Neural Networks Under Optimally Evolved Training Perturbations</papertitle>
              </a>
              <br>
              <strong>Subhajit Chaudhury</strong> and Toshihiko Yamasaki. 
              <br>
              <em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2020.
              <br>
              <a href="https://arxiv.org/abs/2003.06646">arxiv</a> 
              <!-- <a href="https://www.youtube.com/watch?v=bvNpV2Q4rOA">video</a> -->
              <p></p>
              <!--<p>Learn an internal model of observation to estimate rewards without completely learning the dynamics-->
                <!--of the external environment for imitation learning from observations.</p>-->
            </td>
          </tr>

          
          <!--Subha's AAAI Submission-->
          <tr onmouseout="arxiv_vigan_stop()" onmouseover="arxiv_vigan_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='arxiv_vigan_image'><img src='images/arxiv_vigan/before.png'></div>
                <img src='images/arxiv_vigan/before.png'>
              </div>
              <script type="text/javascript">
                function arxiv_vigan_start() {
                  document.getElementById('arxiv_vigan_image').style.opacity = "1";
                }

                function arxiv_vigan_stop() {
                  document.getElementById('arxiv_vigan_image').style.opacity = "0";
                }
                arxiv_vigan_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/pdf/1806.01267.pdf">
                <papertitle>Injective State-Image Mapping facilitates Visual Adversarial Imitation Learning</papertitle>
              </a>
              <br>
              <strong>Subhajit Chaudhury</strong>, Daiki Kimura, Asim Munawar and Ryuki Tachibana
              <br>
              <em>IEEE International Workshop on Multimedia Signal Processing (MMSP)</em>, 2019 <strong>(Oral)</strong>.
              <br>
              <a href="https://arxiv.org/abs/1810.01108">arxiv</a> /
              <a href="https://www.youtube.com/watch?v=bvNpV2Q4rOA">video</a>
              <p></p>
              <!--<p>Learn an internal model of observation to estimate rewards without completely learning the dynamics-->
                <!--of the external environment for imitation learning from observations.</p>-->
            </td>
          </tr>

          <!--Daiki's ICML WS-->
          <tr onmouseout="icml2018_stop()" onmouseover="icml2018_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='icml2018_image'><img src='images/icml2018/before.png'></div>
                <img src='images/icml2018/before.png'>
              </div>
              <script type="text/javascript">
                function icml2018_start() {
                  document.getElementById('icml2018_image').style.opacity = "1";
                }

                function icml2018_stop() {
                  document.getElementById('icml2018_image').style.opacity = "0";
                }
                icml2018_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/pdf/1806.01267.pdf">
                <papertitle>Internal Model from Observations for Reward Shaping</papertitle>
              </a>
              <br>
              Daiki Kimura, <strong>Subhajit Chaudhury</strong>, Ryuki Tachibana and Sakyasingha Dasgupta
              <br>
              <em>International Conference of Machine Learning (ICML), Adaptive Learning Agents Workshop</em>, 2018
              <br>
              <a href="https://arxiv.org/abs/1806.01267">arxiv</a> /
              <a href="bibs/icmlws_2018.bib">bibtex</a>
              <p></p>
              <!--<p>Learn an internal model of observation to estimate rewards without completely learning the dynamics-->
                <!--of the external environment for imitation learning from observations.</p>-->
            </td>
          </tr>

          <!--Milk's ICPR-->
          <tr onmouseout="icpr2018_stop()" onmouseover="icpr2018_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='icpr2018_image'><img src='images/icpr2018/before.png'></div>
                <img src='images/icpr2018/before.png'>
              </div>
              <script type="text/javascript">
                function icpr2018_start() {
                  document.getElementById('icpr2018_image').style.opacity = "1";
                }

                function icpr2018_stop() {
                  document.getElementById('icpr2018_image').style.opacity = "0";
                }
                icpr2018_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <p>
                <a href="https://arxiv.org/pdf/1806.08523.pdf">
                  <papertitle>Focusing on What is Relevant: Time-Series Learning and Understanding using Attention</papertitle>
                </a>
                <br>
                Phongtharin Vinayavekhin, <strong>Subhajit Chaudhury</strong>, Asim Munawar, Don Joven Agravante, Giovanni De Magistris,
                Daiki Kimura and Ryuki Tachibana
                <br>
                <em>International Conference on Pattern Recognition (ICPR)</em>, 2018
                <br>
                <a href="https://arxiv.org/abs/1806.08523">arxiv</a> /
                <a href="bibs/icpr2018.bib">bibtex</a>
                <p></p>
                <!--<p>Temporal attention layer that is capable of selecting the relevant information to perform-->
                  <!--various tasks, including data completion, key-frame detection and classification</p>-->

                <p></p>
                </a>
              </p>
            </td>
          </tr>

          <!--Inoue's ICIP-->
          <tr onmouseout="icip2018_stop()" onmouseover="icip2018_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='icip2018_image'><img src='images/icip2018/after.png'></div>
                <img src='images/icip2018/before.png'>
              </div>
              <script type="text/javascript">
                function icip2018_start() {
                  document.getElementById('icip2018_image').style.opacity = "1";
                }

                function icip2018_stop() {
                  document.getElementById('icip2018_image').style.opacity = "0";
                }
                icip2018_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/pdf/1709.06762.pdf">
                <papertitle>Transfer learning from synthetic to real images using variational auto-encoders
                  for robotic applications</papertitle>
              </a>
              <br>
              Tadanobu Inoue, <strong>Subhajit Chaudhury</strong>, Giovanni De Magistris and Sakyasingha Dasgupta
              <br>
              <em>IEEE International Conference on Image Processing (ICIP)</em>, 2018
              <br>
              <a href="https://arxiv.org/abs/1709.06762">arxiv</a> /
              <a href="https://www.youtube.com/watch?v=Wd-1WU8emkw&t=10s">Video</a> /
              <a href="bibs/icip2018.bib">bibtex</a>
              <p></p>
              <!--<p>Transfering synthetic to real images using a limited dataset of real images while leveraging a large dataset of synthetic images using multiple variational autoencoders.</p>-->
            </td>
          </tr>

          <!--ICMLWS 2017-->
          <tr onmouseout="icmlws2017_stop()" onmouseover="icmlws2017_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='icmlws2017_image'><img src='images/icmlws2017/after.png'></div>
                <img src='images/icmlws2017/before.png'>
              </div>
              <script type="text/javascript">
                function icmlws2017_start() {
                  document.getElementById('icmlws2017_image').style.opacity = "1";
                }

                function icmlws2017_stop() {
                  document.getElementById('icmlws2017_image').style.opacity = "0";
                }
                icmlws2017_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/pdf/1707.00860.pdf">
                <papertitle>Conditional generation of multi-modal data using constrained embedding space mapping</papertitle>
              </a>
              <em>International Conference on Machine Learning (ICML), Implicit Models Workshop</em>, 2017
              <br>

              <a href="https://www.dropbox.com/s/bbw22ya0rs4ceu3/MLSP_Final_Version.pdf?dl=0">
                <papertitle>Text to image generative model using constrained embedding space mapping</papertitle>
              </a>
              <em>IEEE International workshop on Machine learning for Signal Processing (MLSP)</em>, 2017
              <br>
              <br>
              <strong>Subhajit Chaudhury</strong>, Sakyasingha Dasgupta, Asim Munawar, Md. A. Salam Khan and Ryuki Tachibana
              <br>
              <a href="https://arxiv.org/abs/1707.00860">arxiv</a> /
              <a href="https://www.dropbox.com/s/kzbs6qfqfri74t7/ICML_WS_poster_a0.pdf?dl=0">Poster</a> /
              <a href="https://www.dropbox.com/s/asandjnsbr3kpn9/MLSP_talk.pptx?dl=0">Slides</a> /
              <a href="bibs/icmlws2017.bib">bibtex</a>
              <p></p>

            </td>
          </tr>
          
          <!--MVA2017-->
          <tr onmouseout="mva2017_stop()" onmouseover="mva2017_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='mva2017_image'><img src='images/mva2017/after.png'></div>
                <img src='images/mva2017/before.png'>
              </div>
              <script type="text/javascript">
                function mva2017_start() {
                  document.getElementById('mva2017_image').style.opacity = "1";
                }

                function mva2017_stop() {
                  document.getElementById('mva2017_image').style.opacity = "0";
                }
                mva2017_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/pdf/1611.04481.pdf">
                <papertitle>Can fully convolutional networks perform well for general image restoration problems?</papertitle>
              </a>
              <br>
              <strong>Subhajit Chaudhury</strong> and Hiya Roy
              <br>
              <em>International Conference on Machine Vision Applications (MVA)</em>, 2017
              <br>
              <a href="https://arxiv.org/abs/1611.04481">arxiv</a> /
              <a href="https://www.dropbox.com/s/yjcfojot9ya6zt2/IAPR-Poster%20ppt-4.pptx?dl=0">Poster</a> /
              <a href="bibs/mva2017.bib">bibtex</a>
              <p></p>

            </td>
          </tr>

          
          <!--WACV2017-->
          <tr onmouseout="wacv2017_stop()" onmouseover="wacv2017_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='wacv2017_image'><img src='images/wacv2017/after.png'></div>
                <img src='images/wacv2017/before.png'>
              </div>
              <script type="text/javascript">
                function wacv2017_start() {
                  document.getElementById('wacv2017_image').style.opacity = "1";
                }

                function wacv2017_stop() {
                  document.getElementById('wacv2017_image').style.opacity = "0";
                }
                wacv2017_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://ieeexplore.ieee.org/document/7926627/">
                <papertitle>Spatial-Temporal Motion Field Analysis for Crack Detection on Concrete Surfaces</papertitle>
              </a>
              <br>
              <strong>Subhajit Chaudhury</strong>, Gaku Nakano, Jun Takada, Akihiko Iketani
              <br>
              <em>IEEE Winter Conference on Applications of Computer Vision (WACV)</em>, 2017
              <br>
              <a href="https://ieeexplore.ieee.org/document/7926627/">Paper</a> /
              <a href="assets/WACV17-poster.pdf">Poster</a> /
              <a href="bibs/wacv2017.bib">bibtex</a>
              <p></p>

            </td>
          </tr>
          
          
          <!--SASIMI2016-->
          <tr onmouseout="sasimi2016_stop()" onmouseover="sasimi2016_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='sasimi2016_image'><img src='images/sasimi2016/before.png'></div>
                <img src='images/sasimi2016/before.png'>
              </div>
              <script type="text/javascript">
                function sasimi2016_start() {
                  document.getElementById('sasimi2016_image').style.opacity = "1";
                }

                function sasimi2016_stop() {
                  document.getElementById('sasimi2016_image').style.opacity = "0";
                }
                sasimi2016_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="assets/SASIMI_paper.pdf">
                <papertitle>Convolutional Neural Network Layer Re-ordering for Acceleration</papertitle>
              </a>
              <br>
              Vijay Daultani, <strong>Subhajit Chaudhury</strong>, Kazuhisa Ishizaka
              <br>
              <em>Workshop on Synthesis And System Integration of Mixed Information (SASIMI)</em>, 2016
              <br>
              <a href="assets/SASIMI_paper.pdf">Paper</a> /
              <a href="assets/Poster_SASIMI2016.pdf">Poster</a> /
              <a href="bibs/sasimi2016.bib">bibtex</a>
              <p></p>

            </td>
          </tr>
          
          <!--Haptics2014-->
          <tr onmouseout="haptics2014_stop()" onmouseover="haptics2014_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='haptics2014_image'><img src='images/haptics2014/before.png'></div>
                <img src='images/haptics2014/before.png'>
              </div>
              <script type="text/javascript">
                function haptics2014_start() {
                  document.getElementById('haptics2014_image').style.opacity = "1";
                }

                function haptics2014_stop() {
                  document.getElementById('haptics2014_image').style.opacity = "0";
                }
                haptics2014_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="assets/chaudhury2014.pdf">
                <papertitle>Volume Preserving Haptic Pottery</papertitle> <font color="red"><strong>(Oral Presentation)</strong></font>
              </a>
              <br>
              <strong>Subhajit Chaudhury</strong> and Subhasis Chaudhuri
              <br>
              <em>IEEE Haptics Symposium (HAPTICS),</em> 2014
              <br>
              <a href="assets/chaudhury2014.pdf">Paper</a> /
              <a href="https://www.youtube.com/watch?v=CSQsDDbkn64">Video</a> /
              <a href="bibs/haptics2014.bib">bibtex</a>
              <p></p>

            </td>
          </tr>
          
          
          <!--ICVGIP2017-->
          <tr onmouseout="icvgip2014_stop()" onmouseover="icvgip2014_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='icvgip2014_image'><img src='images/icvgip2014/before.png'></div>
                <img src='images/icvgip2014/before.png'>
              </div>
              <script type="text/javascript">
                function icvgip2014_start() {
                  document.getElementById('icvgip2014_image').style.opacity = "1";
                }

                function icvgip2014_stop() {
                  document.getElementById('icvgip2014_image').style.opacity = "0";
                }
                icvgip2014_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="assets/icvgip_final_version.pdf">
                <papertitle>Vision-Based Human Pose Estimation for Virtual Cloth Fitting.</papertitle>
              </a>
              <br>
              Sourav Saha, Pritha Ganguly, and <strong>Subhajit Chaudhury</strong>
              <br>
              <em>Indian Conference on Computer Vision, ICVGIP</em>, 2014
              <br>
              <a href="assets/icvgip_final_version.pdf">Paper</a> /
              <a href="bibs/icvgip2014.bib">bibtex</a>
              <p></p>

            </td>
          </tr>

        </p><hr size="2" align="left" noshade="">
        
        <!-- </p><hr size="2" align="left" noshade=""> -->
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td>
            <heading>Teaching</heading>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
        <tr>
          <td width="25%"><img src="images/signal.png" alt="pacman" width="160" height="160"></td>
          <td width="75%" valign="center">
            <p>
              Teaching Assistant, EE210 Signals and System, IIT Bombay (Spring-2013)
              <br>
              <br>
              Teaching Assistant, EE603 Digital Signal Processing and its application, IIT Bombay (Autumn-2013)
              <br>
              <br>
              Teaching Assistant,  Computer Vision, IIT Bombay (Spring 2014)
              <br>
            </p>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td>
            <br>
            <p align="right">
              <font size="2">
                <a href="https://jonbarron.info/">Original Website Credits</a>
                </font>
            </p>
          </td>
        </tr>
      </table>
      <!--<script type="text/javascript">-->
        <!--var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");-->
        <!--document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));-->
      <!--</script>-->
      <!--<script type="text/javascript">-->
        <!--try {-->
          <!--var pageTracker = _gat._getTracker("UA-7580334-1");-->
          <!--pageTracker._trackPageview();-->
        <!--} catch (err) {}-->
      <!--</script>-->
      </td>
  </tr>
</table>

<!-- </p><hr size="2" align="left" noshade=""> -->

<th scope="col" width=20% height=0%><div align="center">
<a href="https://info.flagcounter.com/Isjg"><img src="https://s01.flagcounter.com/count2/Isjg/bg_FFFFFF/txt_000000/border_CCCCCC/columns_3/maxflags_12/viewers_0/labels_1/pageviews_1/flags_0/percent_0/" alt="Flag Counter" border="0"></a>
</div></th>

</body>

</html>
